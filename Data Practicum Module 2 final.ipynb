{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "fields = [ 'qname', 'hostname', 'group', 'owner', 'job_name',\n",
    "      'job_number', 'account', 'priority', 'submission_time', 'start_time',\n",
    "      'end_time', 'failed', 'exit_status', 'ru_wallclock', 'ru_utime',\n",
    "      'ru_stime', 'ru_maxrss', 'ru_ixrss', 'ru_ismrss', 'ru_idrss',\n",
    "      'ru_isrss', 'ru_minflt', 'ru_majflt', 'ru_nswap', 'ru_inblock',\n",
    "      'ru_oublock', 'ru_msgsnd', 'ru_msgrcv', 'ru_nsignals', 'ru_nvcsw',\n",
    "      'ru_nivcsw', 'project', 'department', 'granted_pe', 'slots',\n",
    "      'task_number', 'cpu', 'mem', 'io', 'category',\n",
    "      'iow', 'pe_taskid', 'maxvmem', 'arid', 'ar_submission_time' ]\n",
    "\n",
    "usecols = ['owner', 'group', 'job_number', 'task_number','granted_pe',\n",
    "        'slots' ,'category','start_time', 'end_time','failed', 'exit_status','submission_time']\n",
    "\n",
    "df=pd.DataFrame( ['owner', 'group', 'job_number', 'task_number','granted_pe',\n",
    "        'slots' ,'category','start_time', 'end_time','failed', 'exit_status'])\n",
    "\n",
    "data=pd.read_csv('accounting-2018-10.dms', sep=':', error_bad_lines=False, header=None,\n",
    "        names=fields, usecols=usecols, encoding = \"ISO-8859-1\")\n",
    "\n",
    "df=pd.DataFrame(data,columns=['owner', 'group', 'job_number', 'task_number','granted_pe',\n",
    "        'slots' ,'category','start_time', 'end_time','failed', 'exit_status','submission_time'])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4-1\n",
    "A typical category field looks like:\n",
    "\n",
    "...:-U campus -u stevendu -l h_data=4G,h_rt=86400,h_vmem=4G -pe single 1:...\n",
    "In the category field, extract the h_data data, covert the value to gigabytes (see below for explanation) and make it a new column.\n",
    "\n",
    "If the value of h_data ends with a “G” or “g”, the data is in the unit of “gigabytes”. If the value ends with “m” or “M”, the data is in the unit of megabytes:\n",
    "\n",
    "20M or 20m  : 20 megabytes\n",
    "4G or 4g    : 4 gigabytes\n",
    "1024        : 1024 bytes\n",
    "For example, if the category field has h_data=2048M,h_rt=86400,exclusive=TRUE, extract the 2048M, and convert it to 2048 / 1024 = 2 (gigabytes). (Recall: 1G = 1024M)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Everest/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/Volumes/Everest/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Volumes/Everest/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "df['h_data']=df['category'].str.extract(\"h_data=(.*.),h_rt\", expand=True)\n",
    "\n",
    "updt = df['h_data']\n",
    "for i in range (0,len(df['h_data'])):\n",
    "    try:\n",
    "        if (updt[i].find('M') != -1.0) or updt[i].find('m') != -1.0 :\n",
    "            updt[i] = updt[i][:-1]\n",
    "            updt[i] = round(float(updt[i]) / 1024,2)\n",
    "            updt[i] = str(updt[i]) + 'G'\n",
    "    except:\n",
    "        continue \n",
    "\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4-2\n",
    "In the category field, extract the h_rt data, which is in seconds. Make a new column for h_rt in the unit of hours. For example, if the h_rt value is 86400, convert it to 86400/(3600*24) = 24 (hours). In this case, the row value in the new h_rt column will be 24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['h_rt']=df['category'].str.extract(\"h_rt=(.*.),h_vmem\", expand=True)\n",
    "df[\"h_rt\"]=df['h_rt'].astype('float')\n",
    "df[\"h_rt\"]=df[('h_rt')]/(3600)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4-3\n",
    "Create a new column called highp. In the category field, if highp=TRUE or highp=true is identified, the row value of highp would be 1. Otherwise highp is 0 in the new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['highp']=df['category'].str.extract(\"highp=(.*.), -pe\")\n",
    "df[\"highp\"]=(df['highp']=='TRUE').astype(int) + (df['highp']=='true').astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4-4\n",
    "Create a new column called exclusive. In the category field, if exclusive=TRUE or exclusive=true is identified, the row value of exclusive would be 1. Otherwise exclusive is 0 in the new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['exclusive']=df['category'].str.extract(\"exclusive=(.*.),h_data\")\n",
    "df[\"exclusive\"]=(df['exclusive']=='TRUE').astype(int) + (df['exclusive']=='true').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4-5\n",
    "Create a new column called h_vmem. Look for its value in the category field. Similar to h_data, convert the values to gigabytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['h_vmem']=df['category'].str.extract(\"h_vmem=(.*.) -pe\", expand=True)\n",
    "\n",
    "updt = df['h_vmem']\n",
    "for i in range (0,len(df['h_vmem'])):\n",
    "     try:\n",
    "            if updt[i].find('INF') != -1.0:\n",
    "                 updt[i]= 0\n",
    "                  \n",
    "            if (updt[i].find('M') != -1.0) or updt[i].find('m') != -1.0 :\n",
    "                updt[i] = updt[i][:-1]\n",
    "                updt[i] = round(float(df2[i]) / 1024,2)\n",
    "                updt[i] = str(updt[i]) + 'G'\n",
    "     except:\n",
    "        continue \n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4-6\n",
    "Create a new column called gpu. Look for the value in the category field. If required_gpu is identified, set the row value to 1. Otherwise the row value is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gpu'] = df['category'].str.contains('gpu')\n",
    "df['gpu'] = df['gpu'].map({True: '1', False: '0'})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4-7\n",
    "Create two new columns. One is named pe. Another one is slot. In the category field, look for the -pe data, e.g. -pe single 1. In this case, put the single (string) in the new pe column, and the value 1 (integer) in the new slot column.\n",
    "\n",
    "If no pe data is found in the category field, enter none for the pe column, and 1 for the slot column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pe']=df['category'].str.extract(\"-pe (.*.) (\\d)\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['slot'] = df['category'].str[-1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4-8\n",
    "Create a new column campus. In the category field, if the value following -U is campus, set the value to 1 (integer). Otherwise, set it to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['campus']=df['category'].str.extract(\"-U (.*.) -u\")\n",
    "df[\"campus\"]=(df['campus']=='campus').astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5\n",
    "The raw data in the start_time, end_time and submission_time are the UNIX epoch time. Convert the data strings to a Pandas (or Python) data objects. The Timestamp function in Pandas can do this easily. See its documentation for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"submission_time\"]=pd.to_datetime(df['submission_time'], unit='s') \n",
    "df[\"start_time\"]=pd.to_datetime(df['start_time'], unit='s') \n",
    "df[\"end_time\"]=pd.to_datetime(df['end_time'], unit='s') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6\n",
    "Create a new column wait_time whose value is the difference of start_time - submission_time.\n",
    "\n",
    "Create a new column wtime (short for “wall-clock time”) whose value is the difference of end_time - start_time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"wait_time\"]=df['start_time']-df['submission_time']\n",
    "df[\"wtime\"]=df['end_time']-df['start_time']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7\n",
    "Identify duplicates and merge them. You can use the Pandas drop_duplicates function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['job_number', 'task_number', 'submission_time'], keep='first', inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8\n",
    "You may or may not find some values in submission_time, start_time or end_time contain dates before year 2018. Drop (delete) these rows from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['submission_time'].dt.year < 2018)]\n",
    "df[(df['start_time'].dt.year < 2018)]\n",
    "df[(df['end_time'].dt.year < 2018)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9\n",
    "Remove these columns that we will not need: ['category', 'qname', 'job_name', 'account', 'project']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['category'], axis=1, inplace=True)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', -1)\n",
    "# print(df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
